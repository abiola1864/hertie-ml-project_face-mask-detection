{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rolled-company",
   "metadata": {},
   "source": [
    "# Face-Mask-Classification Project\n",
    "\n",
    "\n",
    "Authors:\n",
    "+ Tobias Palmowski\n",
    "+ Fabian Metz\n",
    "+ Thilo Sander\n",
    "\n",
    "Date of Midterm-Report: 29.03.2021 <br>\n",
    "Date of final submission: 26.04.2021\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This Jupyter Notebook is the core of the Face-Mask-Classification Project performed in the class \"Machine Learning\" of the Hertie School in Berlin. There is one other Jupyter Notebook which deals with combining the different datasets into one large data set - a task only performed once and therefore outsourced to another file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-friendship",
   "metadata": {},
   "source": [
    "### Data Processing: Pipeline-Building\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "[Short Description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "burning-manhattan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:44:44.194823Z",
     "start_time": "2021-03-27T15:44:44.183840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and set-up Jupyter NoteMasked-Face-Net-Datasetbook.\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "# Imports for dealing with images:\n",
    "import PIL #Pillow (install with \"pip install Pillow\")\n",
    "\n",
    "# to make this notebook's output stable across runs (safety measure)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set path to correct and incorrect data sets for keeping references short later\n",
    "ROOT_DATA = \"01_data\"\n",
    "PATH_DATA_CORRECT = os.path.join(ROOT_DATA + \"/00_raw/Masked-Face-Net-Dataset/CMFD\")\n",
    "PATH_DATA_INCORRECT = os.path.join(ROOT_DATA + \"/00_raw/Masked-Face-Net-Dataset/IMFD\")\n",
    "\n",
    "# Where to save figures\n",
    "ROOT_FIGS = \"02_figures\"\n",
    "TOPIC_ID = \"02_baseline\"\n",
    "IMAGES_PATH = os.path.join(ROOT_FIGS, TOPIC_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Where to save general output (not figures)\n",
    "ROOT_OUTPUT = \"03_output\"\n",
    "TOPIC_ID = \"01_eval_scores\"\n",
    "OUTPUT_PATH = os.path.join(ROOT_OUTPUT, TOPIC_ID)\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "scientific-insulin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.174798Z",
     "start_time": "2021-03-27T11:55:46.159798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open pickle file that contains the directory\n",
    "import pickle\n",
    "pic_data = pickle.load(open(os.path.join(ROOT_DATA + \"/01_cleaned/pic_data_full.pkl\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "coastal-nevada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.209666Z",
     "start_time": "2021-03-27T11:55:46.192710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copying dictionary data into separate data frames\n",
    "rgb_data, labels = pic_data[\"rgb_data\"], pic_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "posted-shanghai",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.228615Z",
     "start_time": "2021-03-27T11:55:46.213654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of rgb_data: (133582, 3072)\n",
      "Dimensions of labels: (133582,)\n"
     ]
    }
   ],
   "source": [
    "# Explore dimensionalities of data frames\n",
    "print(\"Dimensions of rgb_data:\", rgb_data.shape)\n",
    "print(\"Dimensions of labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "happy-academy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.253548Z",
     "start_time": "2021-03-27T11:55:46.230610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into test and training data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rgb_data_train, rgb_data_test, labels_train, labels_test = train_test_split(rgb_data, labels, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-transsexual",
   "metadata": {},
   "source": [
    "### Evaluating multiple untuned classifiers\n",
    "<br>\n",
    "In this section we define an array of initial classifiers and train them on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "legendary-generation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T13:14:50.224067Z",
     "start_time": "2021-03-27T13:14:50.218080Z"
    }
   },
   "outputs": [],
   "source": [
    "#import classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "#define classifiers\n",
    "classifier_RandomForest = RandomForestClassifier(random_state=42)\n",
    "classifier_LinSVC = svm.LinearSVC(max_iter=4000, tol=1e-3, random_state=42) #linear as normal (c based) is impractical using large datasets\n",
    "classifier_DecTree = tree.DecisionTreeClassifier(random_state=42)\n",
    "classifier_SGD = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "# KNN had several hours runtime an kernel always died before finising\n",
    "# classifier_KNN = KNeighborsClassifier(n_neighbors=1)\n",
    "# LogReg hat several hours runtime an kernel always died before finishing\n",
    "# classifier_LogReg = LogisticRegression(max_iter=2000, tol=1e-3,random_state=42)\n",
    "classifiers= [classifier_RandomForest,classifier_LinSVC,classifier_DecTree,classifier_SGD]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-dispatch",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>ATTENTION</b>\n",
    "<p>\n",
    "Clarify role of max_iterations and possible connectd tradeoffs. Current code specified to produce no errors regarding max_iter\n",
    "<br>\n",
    "Clarify wether seed needs to be set individually?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "christian-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefining labels as True False\n",
    "labels_train_tf = (labels_train == 1)\n",
    "labels_test_tf = (labels_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-electronics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:43:38.078336Z",
     "start_time": "2021-03-27T15:43:16.276133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">... Starting RandomForestClassifier\n",
      ">... 3479.13 seconds run time: RandomForestClassifier\n",
      ">... Starting LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thilosander/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "total_start_time = timeit.default_timer()\n",
    "\n",
    "#intialize arrays and dictionaries \n",
    "running = 1\n",
    "evaluation_scores = {} # dictionary\n",
    "confusion_matrices = [] \n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "\n",
    "#training and evaluating classifiers\n",
    "for classifier_x in classifiers:\n",
    "    #Start timer\n",
    "    loop_start_time = timeit.default_timer()\n",
    "    \n",
    "    # Set classifier name and print status\n",
    "    classifier_name = str(classifier_x) # set classifier names\n",
    "    classifier_name = classifier_name[:classifier_name.find(\"(\")] \n",
    "    print (\">... Starting\", classifier_name)\n",
    "    \n",
    "    #Train model\n",
    "    classifier_x.fit(rgb_data_train, labels_train_tf) # train\n",
    "    pred=cross_val_predict(classifier_x, rgb_data_train, labels_train_tf, cv = 3) # cross value prediction with 3 folds\n",
    "    \n",
    "    # store evaluation metrics \n",
    "    ps = precision_score(labels_train_tf, pred).round(3) \n",
    "    rs = recall_score(labels_train_tf, pred).round(3)\n",
    "    cm = confusion_matrix(labels_train_tf, pred)\n",
    "    cvs = cross_val_score(classifier_x, rgb_data_train, labels_train_tf, cv=3, scoring=\"accuracy\").round(3)\n",
    "    cvs_mean = cvs.mean().round(3)\n",
    "    cvs_std = cvs.std().round(5)\n",
    "    \n",
    "    #store confusion matricies in vector\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    #End timer\n",
    "    loop_elapsed = timeit.default_timer() - loop_start_time\n",
    "    \n",
    "    #store evaluation scores in global dicitonary \n",
    "    evaluation_scores[classifier_name]= [ps, rs, cvs, cvs_mean, cvs_std, round(loop_elapsed,2)]\n",
    "    \n",
    "    #store evaluation scores in pkl file to access them even when kernel dies afterwards\n",
    "    file = open(os.path.join(OUTPUT_PATH, \"evaluation_scores.pkl\"),\"wb\")\n",
    "    pickle.dump(evaluation_scores, file)\n",
    "    file.close()\n",
    "    \n",
    "    #Print Status\n",
    "    print(\">...\", round(loop_elapsed, 2) ,\"seconds run time:\", classifier_name)\n",
    "\n",
    "\n",
    "#End timer\n",
    "total_elapsed = timeit.default_timer() - total_start_time\n",
    "print(\"Classifiers all finished. Run-time: \", round(total_elapsed,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-junction",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ATTENTION</b>\n",
    "<p>\n",
    "    \n",
    "+ Variable running is not necessary or?\n",
    "+ Let's rewrite this as a function that does the same --> Easier to rerun the stuff later with only the classifiers we want or if you want to rerun a classifier.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-unknown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:15:17.309381Z",
     "start_time": "2021-03-27T16:15:17.289501Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating and printing a table with the  evaluation scores\n",
    "index = [\"precision score\", \"recall score\", \"cross validation scores\", \"cross validation mean\", \"cross validation std\", \"run time in seconds\"]\n",
    "table_1 = pd.DataFrame(evaluation_scores, index)\n",
    "table_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-intersection",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>ATTENTION</b>\n",
    "<p>\n",
    "Table export needs to be coded. Include Mean and Standard-Deviation of Cross-Evaluation Scores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-learning",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ATTENTION</b>\n",
    "<p>\n",
    "Below: Hard-coded range is always a very bad idea.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-retention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:12:59.803955Z",
     "start_time": "2021-03-27T16:12:59.069212Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating confusion matrices with seaborn heatmaps \n",
    "for i in range(len(evaluation_scores)):\n",
    "    classifier_name = str(classifiers[i]) # set classifier names\n",
    "    classifier_name = classifier_name[:classifier_name.find(\"(\")] \n",
    "    matrix = pd.DataFrame(confusion_matrices[i], columns = [\"classified as no mask\", \"classified as mask\"],\n",
    "                                    index = [\"no mask\", \"mask\"])\n",
    "    \n",
    "    # Actual plot\n",
    "    plt.figure(figsize = (5,5))\n",
    "    colormap = sns.color_palette(\"Reds\")\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(matrix, ax = ax, annot = True, fmt='d', annot_kws={\"size\": 20}, cmap=colormap, cbar=False)\n",
    "    ax.set_title(classifier_name, fontsize= 15)\n",
    "    save_fig(\"{}\".format(classifier_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-comparison",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>ATTENTION</b>\n",
    "<p>\n",
    "Figures need to be improved regarding:\n",
    "    - fontsize\n",
    "    - figure label\n",
    "    - positioning axis labels\n",
    "    - colour?\n",
    "    \n",
    "Figure export needs to be coded.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
