{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unique-joseph",
   "metadata": {},
   "source": [
    "# Face-Mask-Classification Project\n",
    "\n",
    "\n",
    "Authors:\n",
    "+ Tobias Palmowski\n",
    "+ Fabian Metz\n",
    "+ Thilo Sander\n",
    "\n",
    "Date of Midterm-Report: 29.03.2021 <br>\n",
    "Date of final submission: 26.04.2021\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This Jupyter Notebook is the core of the Face-Mask-Classification Project performed in the class \"Machine Learning\" of the Hertie School in Berlin. There is one other Jupyter Notebook which deals with combining the different datasets into one large data set - a task only performed once and therefore outsourced to another file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-evanescence",
   "metadata": {},
   "source": [
    "### Data Processing: Pipeline-Building\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "[Short Description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "owned-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set-up Jupyter Notebook.\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports for dealing with images:\n",
    "import PIL #Pillow (install with \"pip install Pillow\")\n",
    "\n",
    "# to make this notebook's output stable across runs (safety measure)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set path to correct and incorrect data sets for keeping references short later\n",
    "ROOT_DATA = \"01_data/99_dummy_toy_data\"\n",
    "PATH_DATA_CORRECT = os.path.join(ROOT_DATA + \"/correct\")\n",
    "PATH_DATA_INCORRECT = os.path.join(ROOT_DATA + \"/incorrect\")\n",
    "\n",
    "# Where to save possible figures\n",
    "PROJECT_ROOT_DIR = \"02_figures\"\n",
    "CHAPTER_ID = \"01_data_preparation\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "electoral-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pickle file that contains the directory\n",
    "import pickle\n",
    "pic_data = pickle.load(open(os.path.join(ROOT_DATA + \"/cleaned/pic_data.pkl\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "guided-recovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rgb_data': array([[ 46.,  25.,  20., ..., 139., 205., 255.],\n",
       "        [138., 161., 175., ...,  91.,  60.,  58.],\n",
       "        [211., 204., 188., ..., 179., 152.,  97.],\n",
       "        [ 46.,  25.,  20., ..., 139., 205., 255.],\n",
       "        [138., 161., 175., ...,  91.,  60.,  58.],\n",
       "        [211., 204., 188., ..., 179., 152.,  97.]]),\n",
       " 'labels': array([1, 1, 1, 0, 0, 0], dtype=uint8)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring dictionary structure\n",
    "pic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "figured-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying dictionary data into separate data frames\n",
    "rgb_data, labels = pic_data[\"rgb_data\"], pic_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "capital-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of rgb_data: (6, 3145728)\n",
      "Dimensions of labels: (6,)\n"
     ]
    }
   ],
   "source": [
    "# Explore dimensionalities of data frames\n",
    "print(\"Dimensions of rgb_data:\", rgb_data.shape)\n",
    "print(\"Dimensions of labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-adelaide",
   "metadata": {},
   "source": [
    "### Baseline: SGD Classifier\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "[Short Description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "absent-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-vector",
   "metadata": {},
   "source": [
    "### Evaluation of Baseline\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "[Short Description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "civic-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Baseline Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
