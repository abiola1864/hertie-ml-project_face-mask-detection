{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interesting-parking",
   "metadata": {},
   "source": [
    "# Processing Data Download\n",
    "\n",
    "This Jupyter Notebook serves the purpose to transform the downloaded data set (a collection of `.jpg` pictures) into interpretable input for the Machine Learning algorithm. As this has to be done only once, we keep it out of the main Jupyter Notebook that implements the different methods and models on the training and testing data set.\n",
    "\n",
    "Three majors steps have to be performed in this Jupyter Notebook:\n",
    "1. Proper loading of all images from the subdirectories\n",
    "2. Definition of functions that construct the pipeline\n",
    "    + Translate `.jpg` picture into pixels with intensity per pixel\n",
    "    + Creating arrays of corresponding labels\n",
    "    + Combining all arrays into proper dictionary\n",
    "    + Store translated pixel data so that main Jupyter Notebook can access the data\n",
    "3. Running pipeline with different pixel resolutions\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 1. Defintion of where to find files in folders\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civil-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set-up Jupyter Notebook.\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit # for measuring time/code performance\n",
    "import pickle # for storing dictionary in the end\n",
    "import PIL #Python Image Library\n",
    "\n",
    "# to make this notebook's output stable across runs (safety measure)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "renewable-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch between toy and full data\n",
    "full_data_switch_on = False #Set True for full data set and False for Dummy Data set (see comment below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-judges",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action required</b>\n",
    "<p>\n",
    "    \n",
    "You have to set the switch whether you want to use the full dataset (True) or the dummy toy dataset (False). We set aside 100 correct and 100 incorrect pictures into a dummy toy data set in order to test our code faster. For running the algorithm with the dummy toy data everything is included in the GitHub-Repository (in the folder \"01_data/99_dummy_toy_data\").\n",
    "    \n",
    "However, if you want to run the algorithm with the full data set, you have to download the corresponding files under the Dropbox-Link below. The raw data is placed in the Dropbox folder \"00_raw\" (Hint: It is ca. 40,5 GB) and you have to download it into the repository folder \"01_data/00_raw/\".\n",
    "\n",
    "The reason why we cannot directly use the links here is that we do not have figured out yet how to loop through subfolders and files Dropbox online. GitHub does not allow us to upload such an amount of data.\n",
    "<br>\n",
    "Dropbox-Link: https://www.dropbox.com/sh/45vbkq1ihfnhqem/AAADdq6mJKaLsG1w7SDK-QV8a?dl=0    \n",
    "\n",
    "<br>\n",
    "<b>\n",
    "!!!  Be aware: Running this Jupyter Notebook with the full data set requires probably >8 hours of runtime for a 32x32 pixel resolution - depending on your hardware !!!\n",
    "\n",
    "</b>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesbian-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path variables depending on switch\n",
    "if full_data_switch_on == True: \n",
    "    # Set path to full data set of correct and incorrect files\n",
    "    ROOT_DATA = \"01_data/00_raw/\"\n",
    "    PATH_DATA_CORRECT_NVIDIA = os.path.join(ROOT_DATA + \"Masked-Face-Net-Dataset/CMFD\")\n",
    "    PATH_DATA_INCORRECT_NVIDIA = os.path.join(ROOT_DATA + \"Masked-Face-Net-Dataset/IMFD\")\n",
    "    # Set path to second data set\n",
    "    PATH_DATA_KAGGLE = os.path.join(ROOT_DATA + \"Face-Mask-Dataset_Kaggle/train/\")\n",
    "    PATH_LABELS_KAGGLE = os.path.join(ROOT_DATA +\"Face-Mask-Dataset_Kaggle/kaggle_train_labels.csv\")\n",
    "elif full_data_switch_on == False:\n",
    "    # Set path to dummy toy data set of correct and incorrect files\n",
    "    ROOT_DATA = \"01_data/99_dummy_toy_data/\"\n",
    "    PATH_DATA_CORRECT_NVIDIA = os.path.join(ROOT_DATA + \"correct\")\n",
    "    PATH_DATA_INCORRECT_NVIDIA = os.path.join(ROOT_DATA + \"incorrect\")\n",
    "    # Set path to dummy second data set\n",
    "    PATH_DATA_KAGGLE = os.path.join(ROOT_DATA + \"Kaggle_dummy\")\n",
    "    PATH_LABELS_KAGGLE = os.path.join(ROOT_DATA +\"kaggle_train_labels.csv\")\n",
    "else:\n",
    "    raise ValueError(\"Full data switch not correctly defined: Binary value of True or False necessary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "configured-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to list all pictures to include\n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuing-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing and Extracting necessary information of NVIDIA data set\n",
    "\n",
    "# List all file paths in corresponding folder\n",
    "filepaths_correct_NVIDIA = list_files(PATH_DATA_CORRECT_NVIDIA)\n",
    "filepaths_incorrect_NVIDIA = list_files(PATH_DATA_INCORRECT_NVIDIA)\n",
    "\n",
    "# Extract pic ids from files in consideration\n",
    "#Correct pic ids\n",
    "pic_ids_correct_NVIDIA = np.array([])\n",
    "for i in range(len(filepaths_correct_NVIDIA)):\n",
    "    file_short = filepaths_correct_NVIDIA[i].replace(PATH_DATA_CORRECT_NVIDIA + \"/\", \"NVIDIA/\")\n",
    "    pic_ids_correct_NVIDIA = np.append(pic_ids_correct_NVIDIA, file_short)\n",
    "#Incorrect pic ids\n",
    "pic_ids_incorrect_NVIDIA = np.array([])\n",
    "for i in range(len(filepaths_incorrect_NVIDIA)):\n",
    "    file_short = filepaths_incorrect_NVIDIA[i].replace(PATH_DATA_INCORRECT_NVIDIA + \"/\", \"NVIDIA/\")\n",
    "    pic_ids_incorrect_NVIDIA = np.append(pic_ids_incorrect_NVIDIA, file_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "systematic-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing and Extracting necessary information of Kaggle datafile\n",
    "\n",
    "# Load labels csv.file of Kaggle data set\n",
    "labels_kaggle = pd.read_csv(PATH_LABELS_KAGGLE)\n",
    "\n",
    "# List all file path in corresponding folder\n",
    "filepaths_kaggle_all = list_files(PATH_DATA_KAGGLE)\n",
    "\n",
    "# Extract pic ids from files in consideration\n",
    "pic_ids_kaggle = []\n",
    "for itr in range(len(filepaths_kaggle_all)):\n",
    "    pic_ids_kaggle.append(filepaths_kaggle_all[itr].replace(PATH_DATA_KAGGLE, \"KAGGLE\"))\n",
    "\n",
    "# Extract filenames out of pic ids\n",
    "filenames_kaggle = []\n",
    "for itr in range(len(pic_ids_kaggle)):\n",
    "    filenames_kaggle.append(pic_ids_kaggle[itr].replace(\"KAGGLE/\", \"\"))\n",
    "    \n",
    "# Add all information into pandas data frame\n",
    "filenames_kaggle = pd.DataFrame(filenames_kaggle)\n",
    "filenames_kaggle = filenames_kaggle.rename(columns = {0: \"filename\"})\n",
    "filenames_kaggle[\"pic_ids\"] = pic_ids_kaggle\n",
    "filenames_kaggle[\"full_path\"] = filepaths_kaggle_all\n",
    "\n",
    "# Merge with labels set with left joing\n",
    "Left_join_kaggle = pd.merge(filenames_kaggle, \n",
    "                     labels_kaggle, \n",
    "                     on ='filename', \n",
    "                     how ='left')\n",
    "\n",
    "# Translating descriptive labels into True/False\n",
    "Left_join_kaggle[\"label_tf\"] = \"\"\n",
    "for itr in range(len(Left_join_kaggle)):\n",
    "    if Left_join_kaggle[\"label\"][itr] == \"with_mask\":\n",
    "        Left_join_kaggle[\"label_tf\"][itr] = True\n",
    "    elif Left_join_kaggle[\"label\"][itr] == \"without_mask\":\n",
    "        Left_join_kaggle[\"label_tf\"][itr] = False\n",
    "    else:\n",
    "        raise ValueError(\"Check labels: Neither 'with_mask' nor 'without_mask'\")\n",
    "\n",
    "\n",
    "# Separating pandas dataframe into one for correct and one for incorrect\n",
    "pd_data_kaggle_correct = Left_join_kaggle.loc[Left_join_kaggle[\"label_tf\"] == True]\n",
    "pd_data_kaggle_incorrect = Left_join_kaggle.loc[Left_join_kaggle[\"label_tf\"] == False]\n",
    "\n",
    "# Extracting pic ids to numpy arrays for later purposes\n",
    "pic_ids_correct_KAGGLE_np = np.array(pd_data_kaggle_correct[\"pic_ids\"].tolist())\n",
    "pic_ids_incorrect_KAGGLE_np = np.array(pd_data_kaggle_incorrect[\"pic_ids\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "overall-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining filepaths of two data sets\n",
    "filepaths_correct = filepaths_correct_NVIDIA + pd_data_kaggle_correct[\"full_path\"].tolist()\n",
    "filepaths_incorrect = filepaths_incorrect_NVIDIA + pd_data_kaggle_incorrect[\"full_path\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-chemical",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Defining necessary functions that construct the pipeline\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Function for transforming .jpg-fils into numerical arrays\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "statistical-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries/functions\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "\n",
    "# Defining function that performs translation of jpg files into numerical representation\n",
    "def pixel_transformation(target_pixel, correct_switch):\n",
    "    # Correct/Incorrect switch\n",
    "    if correct_switch==True:\n",
    "            \n",
    "        # Run-time information\n",
    "        start_time = timeit.default_timer()\n",
    "        print(\">... Starting pixel transformation for correct pictures for resolution: \", target_pixel, \"x\", target_pixel)\n",
    "\n",
    "        # Initialize emtpy array of fitting length\n",
    "        array_length = target_pixel*target_pixel*3 #Times 3 as we have 3 values (RGB) per pixel\n",
    "        loaded_pics_correct = np.empty([0,array_length])\n",
    "\n",
    "        #Running trough all correctly worn image files\n",
    "        for filename in filepaths_correct:\n",
    "            # open picture\n",
    "            pic = PIL_Image.open(filename)\n",
    "            # Reduce size from original format to target format\n",
    "            pic_resized = pic.resize((target_pixel, target_pixel))\n",
    "            # Extract RGB data\n",
    "            pic_data = np.array(pic_resized)\n",
    "            # Include help array to reshape 3D-array(e.g.: 1024, 1024, 3) into 1D array\n",
    "            help_array = np.reshape(pic_data,(pic_data.size,))\n",
    "            # Stack each array onto each other to have one larger array of shape (#obs,#pixels*3)\n",
    "            loaded_pics_correct = np.vstack((loaded_pics_correct, help_array))\n",
    "        \n",
    "        #End run-time information\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        print(\"Finished\", target_pixel, \"x\", target_pixel ,\"pixel transformation for correct pictures. Run-time in seconds: \", round(elapsed,2))\n",
    " \n",
    "        # Returning\n",
    "        return loaded_pics_correct\n",
    "        \n",
    "  \n",
    "    elif correct_switch==False:\n",
    "            \n",
    "        # Run-time information\n",
    "        start_time = timeit.default_timer()\n",
    "        print(\">... Starting pixel transformation for incorrect pictures for resolution: \", target_pixel, \"x\", target_pixel)\n",
    "\n",
    "        # Initialize emtpy array of fitting length\n",
    "        array_length = target_pixel*target_pixel*3 #Times 3 as we have 3 values (RGB) per pixel\n",
    "        loaded_pics_incorrect = np.empty([0,array_length])\n",
    "\n",
    "        #Running trough all correctly worn image files\n",
    "        for filename in filepaths_incorrect:\n",
    "            # open picture\n",
    "            pic = PIL_Image.open(filename)\n",
    "            # Reduce size from original format to target format\n",
    "            pic_resized = pic.resize((target_pixel, target_pixel))\n",
    "            # Extract RGB data\n",
    "            pic_data = np.array(pic_resized)\n",
    "            # Include help array to reshape 3D-array(e.g.: 1024, 1024, 3) into 1D array\n",
    "            help_array = np.reshape(pic_data,(pic_data.size,))\n",
    "            # Stack each array onto each other to have one larger array of shape (#obs,#pixels*3)\n",
    "            loaded_pics_incorrect = np.vstack((loaded_pics_incorrect, help_array))\n",
    "\n",
    "        #End run-time information\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        print(\"Finished\", target_pixel, \"x\", target_pixel ,\"pixel transformation for incorrect pictures. Run-time in seconds: \", round(elapsed,2))\n",
    "\n",
    "        # Returning\n",
    "        return loaded_pics_incorrect\n",
    "        \n",
    "   \n",
    "    else:\n",
    "        raise ValueError(\"Error: Value for correct_switch muste be True or False!\")\n",
    "        \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-trauma",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Function for creating label vectors\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "differential-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to create label vector\n",
    "\n",
    "def add_labels(pic_array, correct_switch):\n",
    "    # Run-time information\n",
    "    start_time = timeit.default_timer()\n",
    "    print(\">... Starting to create labels vector for array.\")\n",
    "    \n",
    "    # Define label depending on switch\n",
    "    if correct_switch==True:\n",
    "        label_item = 1\n",
    "    elif correct_switch==False:\n",
    "        label_item = 0\n",
    "    else:\n",
    "        raise ValueError(\"Error: Value for correct_switch muste be True or False!\")\n",
    "        \n",
    "    # Initialize array and run for-loop\n",
    "    labels = np.array([])\n",
    "    for itr in range(len(pic_array)):\n",
    "        labels = np.append(labels, label_item)\n",
    "    # Transform to integers\n",
    "    labels = labels.astype(np.uint8)\n",
    "    \n",
    "    # End run-time information\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Finished to create labels vector for array. Label: \",label_item,\". Run-time in seconds: \", round(elapsed,2))\n",
    "    \n",
    "    #Returning values\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-pursuit",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Function for combining arrays into dictionary\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "played-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to combine arrays to dictionary\n",
    "\n",
    "def comb_to_dict(feat_cor, feat_incor, labels_cor, labels_incor):\n",
    "    # Run-time information\n",
    "    start_time = timeit.default_timer()\n",
    "    print(\">... Starting to combine arrays to dictionary.\")\n",
    "    \n",
    "    # combine label arrays\n",
    "    labels = np.array([])\n",
    "    labels = np.append(labels_cor, labels_incor)\n",
    "    \n",
    "    # Combine feature arrays\n",
    "    cleaned_data = np.array([])\n",
    "    cleaned_data = np.vstack((feat_cor, feat_incor))\n",
    "    \n",
    "    # Combine pic id arrays\n",
    "    pic_ids_all = np.array([])\n",
    "    for i in range(len(pic_ids_correct_NVIDIA)):\n",
    "        pic_ids_all = np.append(pic_ids_all, pic_ids_correct_NVIDIA[i])\n",
    "    for i in range(len(pic_ids_correct_KAGGLE_np)):\n",
    "        pic_ids_all = np.append(pic_ids_all, pic_ids_correct_KAGGLE_np[i])   \n",
    "    for i in range(len(pic_ids_incorrect_NVIDIA)):\n",
    "        pic_ids_all = np.append(pic_ids_all, pic_ids_incorrect_NVIDIA[i])\n",
    "    for i in range(len(pic_ids_incorrect_KAGGLE_np)):\n",
    "        pic_ids_all = np.append(pic_ids_all, pic_ids_incorrect_KAGGLE_np[i])\n",
    "    \n",
    "    # Combine data and labels into one dictionary\n",
    "    pic_data = {}\n",
    "    pic_data[\"rgb_data\"] = cleaned_data\n",
    "    pic_data[\"labels\"] = labels\n",
    "    pic_data[\"pic_ids\"] = pic_ids_all\n",
    "    \n",
    "    # End run-time information\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Finished creating dictionary. Run-time in seconds: \", round(elapsed,2))\n",
    "    \n",
    "    #Returning values\n",
    "    return pic_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-sympathy",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Function for storing dictionary with approriate name\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nearby-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function for storing dictionary with appropiate name in appropriate folder\n",
    "def store_dict(pic_dict, target_pixel):\n",
    "    if full_data_switch_on == True: \n",
    "        file = open((\"01_data/01_cleaned/pic_data_full_\"+str(target_pixel)+\".pkl\"),\"wb\")\n",
    "        pickle.dump(pic_dict, file)\n",
    "        file.close()\n",
    "        print(\"Successfully stored in: 01_data/01_cleaned/pic_data_full_\"+str(target_pixel)+\".pkl\")\n",
    "    elif full_data_switch_on == False: \n",
    "        file = open((\"01_data/01_cleaned/pic_data_dummy_toy_\"+str(target_pixel)+\".pkl\"),\"wb\")\n",
    "        pickle.dump(pic_dict, file)\n",
    "        file.close()\n",
    "        print(\"Successfully stored in: 01_data/01_cleaned/pic_data_dummy_toy_\"+str(target_pixel)+\".pkl\")\n",
    "    else:\n",
    "        raise ValueError(\"Full data switch not correctly defined: Binary value of True or False necessary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-cooperative",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Function for storing dictionary with approriate name\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "negative-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to run whole pipeline\n",
    "\n",
    "def pic_pipeline(pixel_res):\n",
    "    # Run-time information\n",
    "    start_time_all = timeit.default_timer()\n",
    "    print(\"\\n\\n>... Starting picture pipeline for resolution: \", pixel_res, \"x\", pixel_res, \"\\n\\n\")\n",
    "    \n",
    "    # Transformation\n",
    "    feat_correct = pixel_transformation(target_pixel=pixel_res, correct_switch=True)\n",
    "    feat_incorrect = pixel_transformation(target_pixel=pixel_res, correct_switch=False)\n",
    "    # Adding labels\n",
    "    labels_correct = add_labels(pic_array=feat_correct, correct_switch=True)\n",
    "    labels_incorrect = add_labels(pic_array=feat_incorrect, correct_switch=False)\n",
    "    # Combining\n",
    "    pic_data = comb_to_dict(feat_cor=feat_correct, \n",
    "                            feat_incor=feat_incorrect, \n",
    "                            labels_cor=labels_correct, \n",
    "                            labels_incor=labels_incorrect)\n",
    "    # Storing\n",
    "    if store_switch == True:\n",
    "        store_dict(pic_dict=pic_data, target_pixel=pixel_res)\n",
    "    elif store_switch == False:\n",
    "        print(\"Be aware. New arrays are not stored.\")\n",
    "    else:\n",
    "        raise ValueError(\"Error. Store Switch must be either True or False!\")\n",
    "    \n",
    "    # End run-time information\n",
    "    elapsed = timeit.default_timer() - start_time_all\n",
    "    print(\"\\n\\nFinished picture pipeline for resultion: \", pixel_res, \"x\", pixel_res, \"Run-time in seconds:\", round(elapsed,2))\n",
    "    \n",
    "    # Store run-time info\n",
    "    run_time_info = {}\n",
    "    run_time_info[str(pixel_res)] = round(elapsed, 2)\n",
    "    if full_data_switch_on == True: \n",
    "        file = open((\"03_output/03_data_prep_run_time/run_time_data_prep_full_\"+str(pixel_res)+\".pkl\"),\"wb\")\n",
    "        pickle.dump(run_time_info, file)\n",
    "        file.close()\n",
    "        print(\"Successfully stored in: 03_output/03_data_prep_run_time/run_time_data_prep_full_\"+str(pixel_res)+\".pkl\")\n",
    "    elif full_data_switch_on == False: \n",
    "        file = open((\"03_output/03_data_prep_run_time/run_time_data_prep_dummy_toy_\"+str(pixel_res)+\".pkl\"),\"wb\")\n",
    "        pickle.dump(run_time_info, file)\n",
    "        file.close()\n",
    "        print(\"Successfully stored in: 03_output/03_data_prep_run_time/run_time_data_prep_dummy_toy_\"+str(pixel_res)+\".pkl\")\n",
    "    else:\n",
    "        raise ValueError(\"Full data switch not correctly defined: Binary value of True or False necessary\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-pixel",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 3. Running full transformation pipeline\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "focal-detector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">... Starting picture pipeline for resolution:  24 x 24 \n",
      "\n",
      "\n",
      ">... Starting pixel transformation for correct pictures for resolution:  24 x 24\n",
      "Finished 24 x 24 pixel transformation for correct pictures. Run-time in seconds:  1.64\n",
      ">... Starting pixel transformation for incorrect pictures for resolution:  24 x 24\n",
      "Finished 24 x 24 pixel transformation for incorrect pictures. Run-time in seconds:  1.66\n",
      ">... Starting to create labels vector for array.\n",
      "Finished to create labels vector for array. Label:  1 . Run-time in seconds:  0.0\n",
      ">... Starting to create labels vector for array.\n",
      "Finished to create labels vector for array. Label:  0 . Run-time in seconds:  0.0\n",
      ">... Starting to combine arrays to dictionary.\n",
      "Finished creating dictionary. Run-time in seconds:  0.0\n",
      "Successfully stored in: 01_data/01_cleaned/pic_data_dummy_toy_24.pkl\n",
      "\n",
      "\n",
      "Finished picture pipeline for resultion:  24 x 24 Run-time in seconds: 3.3\n",
      "Successfully stored in: 03_output/03_run_time_scores/run_time_data_prep_dummy_toy_24.pkl\n",
      "\n",
      "\n",
      " Finished overall pipeline!\n"
     ]
    }
   ],
   "source": [
    "# Defining pixel resolutions to use: All pics will be reshaped quadratically: So 16 will become 16x16 resolution\n",
    "desired_pixel_res = [24]\n",
    "\n",
    "# Define if new run shall be stored (For development of code)\n",
    "store_switch = True\n",
    "\n",
    "\n",
    "for pix in desired_pixel_res:\n",
    "    # Running transformation pipeline incl storing and adding labels\n",
    "    pic_pipeline(pixel_res=pix)\n",
    "    print(\"\\n\\n Finished overall pipeline!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
