{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interesting-parking",
   "metadata": {},
   "source": [
    "# Processing Data Download\n",
    "\n",
    "This Jupyter Notebook serves the purpose to transform the downloaded data set (a collection of `.jpg` pictures) into interpretable input for the Machine Learning algorithm. As this has to be done only once, we keep it out of the main Jupyter Notebook that implements the different methods and models on the training and testing data set.\n",
    "\n",
    "Four steps have to be performed in this Jupyter Notebook:\n",
    "+ Proper loading of all images from the subdirectories\n",
    "+ Turning colored pictures into grayscale pictures\n",
    "+ Translate `.jpg` picture into pixels with intensity per pixel\n",
    "+ Store translated pixel data so that main Jupyter Notebook can access the data\n",
    "\n",
    "\n",
    "### Loading data\n",
    "\n",
    "The data is located in the folder `/01_data/00_raw/Masked-Face-Net-Dataset`. The folder CMFD (Correctly Masked Face Dataset) contains all pictures of the correctly worn facemasks whereas the folder IMFD (Incorrectly Masked Face Dataset) contains all pictures where people wear the facemasks incorrectly. In the folders there are several subdirectories labeled with ascending numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "lesbian-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set-up Jupyter Notebook.\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit # for measuring time/code performance\n",
    "\n",
    "# Imports for dealing with images:\n",
    "import PIL #Pillow (install with \"pip install Pillow\")\n",
    "\n",
    "# to make this notebook's output stable across runs (safety measure)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set path to correct and incorrect data sets for keeping references short later\n",
    "ROOT_DATA = \"01_data/00_raw/Masked-Face-Net-Dataset\"\n",
    "PATH_DATA_CORRECT = os.path.join(ROOT_DATA + \"/CMFD\")\n",
    "PATH_DATA_INCORRECT = os.path.join(ROOT_DATA + \"/IMFD\")\n",
    "\n",
    "# Where to save possible figures\n",
    "PROJECT_ROOT_DIR = \"02_figures\"\n",
    "CHAPTER_ID = \"01_data_preparation\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "attempted-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of all pictures to include\n",
    "import os\n",
    "\n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r\n",
    "\n",
    "filenames_correct = list_files(PATH_DATA_CORRECT)\n",
    "filenames_incorrect = list_files(PATH_DATA_INCORRECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "certified-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time of this cell in seconds:  5.92\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Importing necessary libraries/functions\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "# Set pixel size (--> Large amount pixels increase data massively.) (Original #pixels: 1024x1024)\n",
    "target_pixel = 32\n",
    "array_length = target_pixel*target_pixel*3 #Times three as we have three values (RGB) per pixel\n",
    "\n",
    "# Initalize and Load Correct pics\n",
    "loaded_pics_correct = np.empty([0,array_length])\n",
    "\n",
    "for filename in filenames_correct:\n",
    "    # open picture\n",
    "    pic = PIL_Image.open(filename)\n",
    "    # Reduce size from original format to target format\n",
    "    pic_resized = pic.resize((target_pixel, target_pixel))\n",
    "    # Extract RGB data\n",
    "    pic_data = np.array(pic_resized)\n",
    "    # Include help array to reshape 3D-array(e.g.: 1024, 1024, 3) into 1D array\n",
    "    help_array = np.reshape(pic_data,(pic_data.size,))\n",
    "    # Stack each array onto each other to have one larger array of shape (#obs,#pixels*3)\n",
    "    loaded_pics_correct = np.vstack((loaded_pics_correct, help_array))\n",
    "\n",
    "# Initalize and Load Incorrect pics\n",
    "loaded_pics_incorrect = np.empty([0,array_length])\n",
    "\n",
    "for filename in filenames_incorrect:\n",
    "    # open picture\n",
    "    pic = PIL_Image.open(filename)\n",
    "    # Reduce size from original format to target format\n",
    "    pic_resized = pic.resize((target_pixel, target_pixel))\n",
    "    # Extract RGB data\n",
    "    pic_data = np.array(pic_resized)\n",
    "    # Include help array to reshape 3D-array(e.g.: 1024, 1024, 3) into 1D array\n",
    "    help_array = np.reshape(pic_data,(pic_data.size,))\n",
    "    # Stack each array onto each other to have one larger array of shape (#obs,#pixels*3)\n",
    "    loaded_pics_incorrect = np.vstack((loaded_pics_incorrect, help_array))\n",
    "\n",
    "#End timer\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Run-time of this cell in seconds: \", round(elapsed,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-remedy",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Place to work on</b>\n",
    "<p>\n",
    "    \n",
    "+ Write a function that takes different target pixels and creates different pickel outputs in the end. (In order to perform different test.)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-cycle",
   "metadata": {},
   "source": [
    "### Adding labels and combining into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "intensive-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct pictures\n",
    "label_item = 1\n",
    "# Get length of pictures included\n",
    "len(loaded_pics_correct)\n",
    "labels_correct = np.array([])\n",
    "for itr in range(len(loaded_pics_correct)):\n",
    "    labels_correct = np.append(labels_correct, label_item)\n",
    "\n",
    "# Transform to integers\n",
    "labels_correct = labels_correct.astype(np.uint8)\n",
    "\n",
    "# Incorrect pictures\n",
    "label_item = 0\n",
    "# Get length of pictures included\n",
    "len(loaded_pics_incorrect)\n",
    "labels_incorrect = np.array([])\n",
    "for itr in range(len(loaded_pics_incorrect)):\n",
    "    labels_incorrect = np.append(labels_incorrect, label_item)\n",
    "\n",
    "# Transform to integers\n",
    "labels_incorrect = labels_incorrect.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "respective-demographic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "inner-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining labels into one array\n",
    "labels = np.array([])\n",
    "labels = np.append(labels_correct, labels_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sound-tongue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "unusual-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = np.array([])\n",
    "cleaned_data = np.vstack((loaded_pics_correct, loaded_pics_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "suspected-nursery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3072)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "streaming-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_data = {}\n",
    "pic_data[\"rgb_data\"] = cleaned_data\n",
    "pic_data[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-pixel",
   "metadata": {},
   "source": [
    "### Storing Pic data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "focal-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open((\"01_data/01_cleaned/pic_data_full.pkl\"),\"wb\")\n",
    "pickle.dump(pic_data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-firewall",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Place to work on</b>\n",
    "<p>\n",
    "Find more efficient way of storing data. Currently six pictures of combined 1.8 MB are transformed to csv files of 151 MB. ~Factor 84 in disk space (--> 40.9 GB get to 3,431 GB of data) - When 1024X1024 pixels are used.\n",
    "    \n",
    "Proposed pixel combination to run at first: (16x16, 32x32, 64x64) --> Reduces 1.8 MB of the six pictures to only 37 to 590 kB at max (reduction of factor 48 to 3 --> overall data reduced to 0.85 GB or 13.6 GB) \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
