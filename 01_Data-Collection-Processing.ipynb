{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interesting-parking",
   "metadata": {},
   "source": [
    "# Processing Data Download\n",
    "\n",
    "This Jupyter Notebook serves the purpose to transform the downloaded data set (a collection of `.jpg` pictures) into interpretable input for the Machine Learning algorithm. As this has to be done only once, we keep it out of the main Jupyter Notebook that implements the different methods and models on the training and testing data set.\n",
    "\n",
    "Four steps have to be performed in this Jupyter Notebook:\n",
    "+ Proper loading of all images from the subdirectories\n",
    "+ Translate `.jpg` picture into pixels with intensity per pixel\n",
    "+ Creating vectors of corresponding labels\n",
    "+ Store translated pixel data so that main Jupyter Notebook can access the data\n",
    "\n",
    "\n",
    "### Loading data\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "civil-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and set-up Jupyter Notebook.\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit # for measuring time/code performance\n",
    "import pickle # for storing dictionary in the end\n",
    "import PIL #Python Image Library\n",
    "\n",
    "# to make this notebook's output stable across runs (safety measure)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "renewable-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch between toy and full data\n",
    "full_data_switch_on = False #Set True for full data set and False for Dummy Data set (see comment below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-judges",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action required</b>\n",
    "<p>\n",
    "    \n",
    "You have to set the switch whether you want to use the full dataset (True) or the dummy toy dataset (False). We set aside 100 correct and 100 incorrect pictures into a dummy toy data set in order to test our code faster. For running the algorithm with the dummy toy data everything is included in the GitHub-Repository (in the folder \"01_data/99_dummy_toy_data\").\n",
    "    \n",
    "However, if you want to run the algorithm with the full data set, you have to download the corresponding files under the Dropbox-Link below. The raw data is placed in the Dropbox folder \"00_raw\" (Hint: It is ca. 40,5 GB) and you have to download it into the repository folder \"01_data/00_raw/\".\n",
    "\n",
    "The reason why we cannot directly use the links here is that we do not have figured out yet how to loop through subfolders and files Dropbox online. GitHub does not allow us to upload such an amount of data.\n",
    "<br>\n",
    "Dropbox-Link: https://www.dropbox.com/sh/45vbkq1ihfnhqem/AAADdq6mJKaLsG1w7SDK-QV8a?dl=0    \n",
    "\n",
    "<br>\n",
    "<b>\n",
    "!!!  Be aware: Running this Jupyter Notebook with the full data set requires probably >8 hours of runtime - depending on your hardware !!!\n",
    "\n",
    "</b>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lesbian-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path variables depending on switch\n",
    "if full_data_switch_on == True: \n",
    "    # Set path to full data set of correct and incorrect files\n",
    "    ROOT_DATA = \"01_data/00_raw/Masked-Face-Net-Dataset\"\n",
    "    PATH_DATA_CORRECT = os.path.join(ROOT_DATA + \"/CMFD\")\n",
    "    PATH_DATA_INCORRECT = os.path.join(ROOT_DATA + \"/IMFD\")\n",
    "else:\n",
    "    # Set path to dummy toy data set of correct and incorrect files\n",
    "    ROOT_DATA = \"01_data/99_dummy_toy_data\"\n",
    "    PATH_DATA_CORRECT = os.path.join(ROOT_DATA + \"/correct\")\n",
    "    PATH_DATA_INCORRECT = os.path.join(ROOT_DATA + \"/incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attempted-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of all pictures to include\n",
    "import os\n",
    "\n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    return r\n",
    "\n",
    "filenames_correct = list_files(PATH_DATA_CORRECT)\n",
    "filenames_incorrect = list_files(PATH_DATA_INCORRECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-chemical",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Transform .jpg-fils into numerical arrays\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "certified-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-time of this cell in seconds:  3.16\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Importing necessary libraries/functions\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "# Set pixel size (--> Large amount pixels increase data massively.) (Original #pixels: 1024x1024)\n",
    "target_pixel = 32\n",
    "array_length = target_pixel*target_pixel*3 #Times three as we have three values (RGB) per pixel\n",
    "\n",
    "# Initalize and Load Correct pics\n",
    "loaded_pics_correct = np.empty([0,array_length])\n",
    "\n",
    "for filename in filenames_correct:\n",
    "    # open picture\n",
    "    pic = PIL_Image.open(filename)\n",
    "    # Reduce size from original format to target format\n",
    "    pic_resized = pic.resize((target_pixel, target_pixel))\n",
    "    # Extract RGB data\n",
    "    pic_data = np.array(pic_resized)\n",
    "    # Include help array to reshape 3D-array(e.g.: 1024, 1024, 3) into 1D array\n",
    "    help_array = np.reshape(pic_data,(pic_data.size,))\n",
    "    # Stack each array onto each other to have one larger array of shape (#obs,#pixels*3)\n",
    "    loaded_pics_correct = np.vstack((loaded_pics_correct, help_array))\n",
    "\n",
    "# Initalize and Load Incorrect pics\n",
    "loaded_pics_incorrect = np.empty([0,array_length])\n",
    "\n",
    "for filename in filenames_incorrect:\n",
    "    # open picture\n",
    "    pic = PIL_Image.open(filename)\n",
    "    # Reduce size from original format to target format\n",
    "    pic_resized = pic.resize((target_pixel, target_pixel))\n",
    "    # Extract RGB data\n",
    "    pic_data = np.array(pic_resized)\n",
    "    # Include help array to reshape 3D-array(e.g.: 1024, 1024, 3) into 1D array\n",
    "    help_array = np.reshape(pic_data,(pic_data.size,))\n",
    "    # Stack each array onto each other to have one larger array of shape (#obs,#pixels*3)\n",
    "    loaded_pics_incorrect = np.vstack((loaded_pics_incorrect, help_array))\n",
    "\n",
    "#End timer\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Run-time of this cell in seconds: \", round(elapsed,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-remedy",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Place to work on</b>\n",
    "<p>\n",
    "    \n",
    "+ Write a function that takes different target pixels and creates different pickel outputs in the end. (In order to perform different test.)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-cycle",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Adding labels and combining into one data frame\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intensive-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct pictures\n",
    "label_item = 1\n",
    "# Get length of pictures included\n",
    "len(loaded_pics_correct)\n",
    "labels_correct = np.array([])\n",
    "for itr in range(len(loaded_pics_correct)):\n",
    "    labels_correct = np.append(labels_correct, label_item)\n",
    "\n",
    "# Transform to integers\n",
    "labels_correct = labels_correct.astype(np.uint8)\n",
    "\n",
    "# Incorrect pictures\n",
    "label_item = 0\n",
    "# Get length of pictures included\n",
    "len(loaded_pics_incorrect)\n",
    "labels_incorrect = np.array([])\n",
    "for itr in range(len(loaded_pics_incorrect)):\n",
    "    labels_incorrect = np.append(labels_incorrect, label_item)\n",
    "\n",
    "# Transform to integers\n",
    "labels_incorrect = labels_incorrect.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "inner-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining labels into one array\n",
    "labels = np.array([])\n",
    "labels = np.append(labels_correct, labels_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unusual-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two dataset of correct and incorrect worn masks\n",
    "cleaned_data = np.array([])\n",
    "cleaned_data = np.vstack((loaded_pics_correct, loaded_pics_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "streaming-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data and labels into one dictionary\n",
    "pic_data = {}\n",
    "pic_data[\"rgb_data\"] = cleaned_data\n",
    "pic_data[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-pixel",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Storing Pic data and labels\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "focal-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary to make it accesible for other Jupyter Notebook\n",
    "if full_data_switch_on == True: \n",
    "    file = open((\"01_data/01_cleaned/pic_data_full.pkl\"),\"wb\")\n",
    "    pickle.dump(pic_data, file)\n",
    "    file.close()\n",
    "else: \n",
    "    file = open((\"01_data/01_cleaned/pic_data_dummy_toy.pkl\"),\"wb\")\n",
    "    pickle.dump(pic_data, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-firewall",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Place to work on</b>\n",
    "<p>\n",
    "In the end, much of this process will be rewritten as functions to run different pixel resolutions and save them in different files automatically.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
