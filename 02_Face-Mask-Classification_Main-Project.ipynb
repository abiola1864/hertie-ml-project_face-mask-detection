{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rolled-company",
   "metadata": {},
   "source": [
    "# Face-Mask-Classification Project\n",
    "\n",
    "\n",
    "Authors:\n",
    "+ Tobias Palmowski\n",
    "+ Fabian Metz\n",
    "+ Thilo Sander\n",
    "\n",
    "Date of Midterm-Report: 29.03.2021 <br>\n",
    "Date of final submission: 26.04.2021\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This Jupyter Notebook is the core of the Face-Mask-Classification Project performed in the class \"Machine Learning\" of the Hertie School in Berlin. There is one other Jupyter Notebook which deals with combining the different datasets into one large data set - a task only performed once and therefore outsourced to another file.\n",
    "\n",
    "The following code is losely based on the chapter \"Classification\" from the book \"Hands-on Machine Learning with Scikit-Learn, Keras, and Tensorflow\" by Aurélien Géron.\n",
    "\n",
    "We included several hints were we are working on in yellow warning boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-friendship",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Preparation\n",
    "\n",
    "<br>\n",
    "This part loads the necessary libraries and packages as well as setting the Input and Output Directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revolutionary-things",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:44:44.194823Z",
     "start_time": "2021-03-27T15:44:44.183840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and set-up Jupyter NoteMasked-Face-Net-Datasetbook.\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns # for plotting\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import timeit # To keep track of calculation time\n",
    "import PIL #Python Image Library\n",
    "import pickle\n",
    "\n",
    "# to make this notebook's output stable across runs (safety measure)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "appointed-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch between toy and full data\n",
    "full_data_switch_on = False #Set True for full data set and False for Dummy Data set (see comment below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-protection",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action required</b>\n",
    "<p>\n",
    "    \n",
    "You have to set the switch whether you want to use the full dataset (True) or the dummy toy dataset (False). We set aside 100 correct and 100 incorrect pictures into a dummy toy data set in order to test our code faster. For running the algorithm with the dummy toy data everything is included in the GitHub-Repository (in the folder \"01_data/99_dummy_toy_data\"). The corresponding .pkl-file that include the output of the first Jupyter Notebook is included in the repository as well (in the folder \"01_data/01_cleaned/\")\n",
    "    \n",
    "However, if you want to run the algorithm with the full data set, you have to download the corresponding files under the Dropbox-Link below. The raw data is placed in the Dropbox folder \"00_raw\" (Hint: It is ca. 40,5 GB) and you have to download it into the repository folder \"01_data/00_raw/\". The corresponding pickle file (ca. 3,3 GB) is also available in the Dropbox-Folder under \"01_cleaned\". This file has to be placed in the corresponding repository folder to make this code run \"01_data/01_cleaned/\".\n",
    "\n",
    "The reason why we cannot directly use the links here is that we do not have figured out yet how to loop through subfolders and files Dropbox online. GitHub does not allow us to upload such an amount of data.\n",
    "<br>\n",
    "Dropbox-Link: https://www.dropbox.com/sh/45vbkq1ihfnhqem/AAADdq6mJKaLsG1w7SDK-QV8a?dl=0    \n",
    "\n",
    "<br>\n",
    "<b>\n",
    "!!!  Be aware: Running this Jupyter Notebook with the full data set requires several hours of runtime depending on your hardware !!!\n",
    "\n",
    "</b>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "burning-manhattan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:44:44.194823Z",
     "start_time": "2021-03-27T15:44:44.183840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting path variables depending on switch\n",
    "if full_data_switch_on == True: \n",
    "    # Set path to full data set of correct and incorrect files\n",
    "    ROOT_DATA = \"01_data/00_raw/Masked-Face-Net-Dataset\"\n",
    "    PATH_DATA_CORRECT = os.path.join(ROOT_DATA + \"/CMFD\")\n",
    "    PATH_DATA_INCORRECT = os.path.join(ROOT_DATA + \"/IMFD\")\n",
    "else:\n",
    "    # Set path to dummy toy data set of correct and incorrect files\n",
    "    ROOT_DATA = \"01_data/99_dummy_toy_data\"\n",
    "    PATH_DATA_CORRECT = os.path.join(ROOT_DATA + \"/correct\")\n",
    "    PATH_DATA_INCORRECT = os.path.join(ROOT_DATA + \"/incorrect\")\n",
    "\n",
    "# Where to save figures\n",
    "ROOT_FIGS = \"02_figures\"\n",
    "TOPIC_ID = \"02_baseline\"\n",
    "IMAGES_PATH = os.path.join(ROOT_FIGS, TOPIC_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Where to save general output (not figures)\n",
    "ROOT_OUTPUT = \"03_output\"\n",
    "TOPIC_ID = \"01_eval_scores\"\n",
    "OUTPUT_PATH = os.path.join(ROOT_OUTPUT, TOPIC_ID)\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-update",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Data Loading and Splitting\n",
    "\n",
    "<br>\n",
    "This part loads the necessary libraries and packages as well as setting the Input and Output Directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scientific-insulin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.174798Z",
     "start_time": "2021-03-27T11:55:46.159798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open pickle file containing the numerical data (depending on switch)\n",
    "if full_data_switch_on == True: \n",
    "    pic_data = pickle.load(open((\"01_data/01_cleaned/pic_data_full.pkl\"),\"rb\"))\n",
    "else: \n",
    "    pic_data = pickle.load(open((\"01_data/01_cleaned/pic_data_dummy_toy_32.pkl\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-scene",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Action required</b>\n",
    "<p>\n",
    "    \n",
    "If you want to run the algorithm with the full data set, you have to download the corresponding pickle file (ca. 3,3 GB) from the Dropbox-Folder under \"01_cleaned\". This file has to be placed in the corresponding repository folder to make this code run \"01_data/01_cleaned/\".\n",
    "<br>\n",
    "Dropbox-Link: https://www.dropbox.com/sh/45vbkq1ihfnhqem/AAADdq6mJKaLsG1w7SDK-QV8a?dl=0    \n",
    "\n",
    "<br>\n",
    "<b>\n",
    "!!!  Be aware: Running the this Jupyter Notebook with the full data set requires several hours of runtime depending on your hardware !!!\n",
    "\n",
    "</b>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coastal-nevada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.209666Z",
     "start_time": "2021-03-27T11:55:46.192710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copying dictionary data into separate data frames\n",
    "rgb_data, labels, pic_ids = pic_data[\"rgb_data\"], pic_data[\"labels\"], pic_data[\"pic_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "posted-shanghai",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.228615Z",
     "start_time": "2021-03-27T11:55:46.213654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of rgb_data: (200, 3072)\n",
      "Dimensions of labels: (200,)\n",
      "Dimensions of pic_ids: (200,)\n"
     ]
    }
   ],
   "source": [
    "# Explore dimensionalities of data frames\n",
    "print(\"Dimensions of rgb_data:\", rgb_data.shape)\n",
    "print(\"Dimensions of labels:\", labels.shape)\n",
    "print(\"Dimensions of pic_ids:\", pic_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "happy-academy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T11:55:46.253548Z",
     "start_time": "2021-03-27T11:55:46.230610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into test and training data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rgb_data_train, rgb_data_test, labels_train, labels_test, pic_ids_train, pic_ids_test = train_test_split(rgb_data, labels, pic_ids, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-transsexual",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Evaluating multiple untuned classifiers\n",
    "<br>\n",
    "In this section we define an array of initial classifiers and train them on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legendary-generation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T13:14:50.224067Z",
     "start_time": "2021-03-27T13:14:50.218080Z"
    }
   },
   "outputs": [],
   "source": [
    "#import classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "#define classifiers\n",
    "classifier_RandomForest = RandomForestClassifier(random_state=42)\n",
    "classifier_LinSVC = svm.LinearSVC(max_iter=4000, tol=1e-3, random_state=42) #linear as normal (c based) is impractical using large datasets\n",
    "classifier_DecTree = tree.DecisionTreeClassifier(random_state=42)\n",
    "classifier_SGD = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "# KNN had several hours runtime and kernel always died before finising\n",
    "# classifier_KNN = KNeighborsClassifier(n_neighbors=1)\n",
    "# LogReg hat several hours runtime and kernel always died before finishing\n",
    "# classifier_LogReg = LogisticRegression(max_iter=2000, tol=1e-3,random_state=42)\n",
    "classifiers= [classifier_RandomForest,classifier_LinSVC,classifier_DecTree,classifier_SGD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "christian-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefining labels as True False\n",
    "labels_train_tf = (labels_train == 1)\n",
    "labels_test_tf = (labels_test == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stretch-electronics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T15:43:38.078336Z",
     "start_time": "2021-03-27T15:43:16.276133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">... Starting RandomForestClassifier\n",
      ">... 1.01 seconds run time: RandomForestClassifier\n",
      ">... Starting LinearSVC\n",
      ">... 5.1 seconds run time: LinearSVC\n",
      ">... Starting DecisionTreeClassifier\n",
      ">... 0.3 seconds run time: DecisionTreeClassifier\n",
      ">... Starting SGDClassifier\n",
      ">... 0.06 seconds run time: SGDClassifier\n",
      "Classifiers all finished. Run-time:  6.47\n"
     ]
    }
   ],
   "source": [
    "# Start total timer\n",
    "total_start_time = timeit.default_timer()\n",
    "\n",
    "#intialize arrays and dictionaries \n",
    "evaluation_scores = {} # dictionary\n",
    "confusion_matrices = [] \n",
    "\n",
    "# Import metrics and validation methods\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "\n",
    "#training and evaluating classifiers\n",
    "for classifier_x in classifiers:\n",
    "    #Start timer\n",
    "    loop_start_time = timeit.default_timer()\n",
    "    \n",
    "    # Set classifier name and print status\n",
    "    classifier_name = str(classifier_x) # set classifier names\n",
    "    classifier_name = classifier_name[:classifier_name.find(\"(\")] \n",
    "    print (\">... Starting\", classifier_name)\n",
    "    \n",
    "    #Train model\n",
    "    classifier_x.fit(rgb_data_train, labels_train_tf) # train\n",
    "    pred=cross_val_predict(classifier_x, rgb_data_train, labels_train_tf, cv = 3) # cross value prediction with 3 folds\n",
    "    \n",
    "    # store evaluation metrics \n",
    "    ps = precision_score(labels_train_tf, pred).round(3) \n",
    "    rs = recall_score(labels_train_tf, pred).round(3)\n",
    "    cm = confusion_matrix(labels_train_tf, pred)\n",
    "    cvs = cross_val_score(classifier_x, rgb_data_train, labels_train_tf, cv=3, scoring=\"accuracy\").round(3)\n",
    "    cvs_mean = cvs.mean().round(3)\n",
    "    cvs_std = cvs.std().round(5)\n",
    "    \n",
    "    #store confusion matricies in vector\n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    #End timer\n",
    "    loop_elapsed = timeit.default_timer() - loop_start_time\n",
    "    \n",
    "    #store evaluation scores in global dicitonary \n",
    "    evaluation_scores[classifier_name]= [ps, rs, cvs, cvs_mean, cvs_std, round(loop_elapsed,2)]\n",
    "    \n",
    "    #store evaluation scores in pkl file to access them even when kernel dies afterwards\n",
    "    if full_data_switch_on == True: \n",
    "        file = open(os.path.join(OUTPUT_PATH, \"evaluation_scores.pkl\"),\"wb\")\n",
    "        pickle.dump(evaluation_scores, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        file = open(os.path.join(OUTPUT_PATH, \"evaluation_scores_toy_dummy.pkl\"),\"wb\")\n",
    "        pickle.dump(evaluation_scores, file)\n",
    "        file.close()\n",
    "    \n",
    "    #Print Status\n",
    "    print(\">...\", round(loop_elapsed, 2) ,\"seconds run time:\", classifier_name)\n",
    "\n",
    "\n",
    "#End timer\n",
    "total_elapsed = timeit.default_timer() - total_start_time\n",
    "print(\"Classifiers all finished. Run-time: \", round(total_elapsed,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beautiful-injection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "coral-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pics ids, labels and predicted values\n",
    "output_array = np.c_[pic_ids_train, labels_train_tf, pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "presidential-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create error array with specific error type\n",
    "err_type_arr = np.array([])\n",
    "for i in range(len(output_array)):\n",
    "    if output_array[i,1] == \"True\" and output_array[i,2] == \"False\":\n",
    "        err_type_arr = np.append(err_type_arr, \"False negative\")\n",
    "    elif output_array[i,1] == \"False\" and output_array[i,2] == \"True\":\n",
    "        err_type_arr = np.append(err_type_arr, \"False positive\")\n",
    "    else:\n",
    "        err_type_arr = np.append(err_type_arr, \"No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "exterior-prerequisite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename picture ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Error Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>00025_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>00031_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>00032_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00033_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>00036_Mask_Nose_Mouth.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>00055_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>00066_Mask_Nose_Mouth.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>00071_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>00076_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>00107_Mask_Mouth_Chin.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>00111_Mask_Nose_Mouth.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>00011_Mask.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>00048_Mask.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>00054_Mask.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>00084_Mask.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00091_Mask.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>00100_Mask.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Filename picture ID  Label Predicted      Error Type\n",
       "36   00025_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "137  00031_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "167  00032_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "18   00033_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "179  00036_Mask_Nose_Mouth.jpg  False      True  False positive\n",
       "47   00055_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "113  00066_Mask_Nose_Mouth.jpg  False      True  False positive\n",
       "83   00071_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "136  00076_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "59   00107_Mask_Mouth_Chin.jpg  False      True  False positive\n",
       "102  00111_Mask_Nose_Mouth.jpg  False      True  False positive\n",
       "176             00011_Mask.jpg   True     False  False negative\n",
       "166             00048_Mask.jpg   True     False  False negative\n",
       "153             00054_Mask.jpg   True     False  False negative\n",
       "69              00084_Mask.jpg   True     False  False negative\n",
       "7               00091_Mask.jpg   True     False  False negative\n",
       "87              00100_Mask.jpg   True     False  False negative"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine error into and output array into pandas data frame\n",
    "error_table_pd = pd.DataFrame(output_array)\n",
    "error_table_pd.rename(columns = {0:'Filename picture ID', 1:\"Label\", 2:\"Predicted\"}, inplace = True)\n",
    "error_table_pd[\"Error Type\"] = err_type_arr\n",
    "filter_options = [\"False positive\", \"False negative\"]\n",
    "error_table_pd.loc[error_table_pd[\"Error Type\"].isin(filter_options)].sort_values(by=[\"Label\", \"Filename picture ID\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-junction",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ATTENTION</b>\n",
    "<p>\n",
    "    \n",
    "+ For loop that encompasses training and validating will be rewritten as function so that we can easier call it over and over again.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-stanley",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Creating output\n",
    "<br>\n",
    "In this section the output is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-unknown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:15:17.309381Z",
     "start_time": "2021-03-27T16:15:17.289501Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating and printing a table with the  evaluation scores\n",
    "index = [\"precision score\", \"recall score\", \"cross validation scores\", \"cross validation mean\", \"cross validation std\", \"run time in seconds\"]\n",
    "table_1 = pd.DataFrame(evaluation_scores, index)\n",
    "table_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-learning",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ATTENTION</b>\n",
    "<p>\n",
    "Table above will be redesigned in order to save it properly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-deficit",
   "metadata": {},
   "source": [
    " Use plot sklearn.metrics below more heavily: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics --->Plotting\n",
    " \n",
    " ---> Visualizations: https://scikit-learn.org/stable/visualizations.html#visualizations\n",
    " \n",
    " metrics.plot_confusion_matrix(estimator, X, …)\n",
    "\t\n",
    "\n",
    "Plot Confusion Matrix.\n",
    "\n",
    "metrics.plot_det_curve(estimator, X, y, *[, …])\n",
    "\t\n",
    "\n",
    "Plot detection error tradeoff (DET) curve.\n",
    "\n",
    "metrics.plot_precision_recall_curve(…[, …])\n",
    "\t\n",
    "\n",
    "Plot Precision Recall Curve for binary classifiers.\n",
    "\n",
    "metrics.plot_roc_curve(estimator, X, y, *[, …])\n",
    "\t\n",
    "\n",
    "Plot Receiver operating characteristic (ROC) curve.\n",
    "\n",
    "\n",
    "metrics.ConfusionMatrixDisplay(…[, …])\n",
    "\t\n",
    "\n",
    "Confusion Matrix visualization.\n",
    "\n",
    "metrics.DetCurveDisplay(*, fpr, fnr[, …])\n",
    "\t\n",
    "\n",
    "DET curve visualization.\n",
    "\n",
    "metrics.PrecisionRecallDisplay(precision, …)\n",
    "\t\n",
    "\n",
    "Precision Recall visualization.\n",
    "\n",
    "metrics.RocCurveDisplay(*, fpr, tpr[, …])\n",
    "\t\n",
    "\n",
    "ROC Curve visualization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-retention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T16:12:59.803955Z",
     "start_time": "2021-03-27T16:12:59.069212Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating confusion matrices with seaborn heatmaps\n",
    "if full_data_switch_on == True: \n",
    "    for i in range(len(evaluation_scores)):\n",
    "        classifier_name = str(classifiers[i]) # set classifier names\n",
    "        classifier_name = classifier_name[:classifier_name.find(\"(\")] \n",
    "        matrix = pd.DataFrame(confusion_matrices[i], columns = [\"classified as no mask\", \"classified as mask\"],\n",
    "                                        index = [\"no mask\", \"mask\"])\n",
    "\n",
    "        # Actual plot with seaborn\n",
    "        plt.figure(figsize = (5,5))\n",
    "        colormap = sns.color_palette(\"Reds\")\n",
    "        ax = plt.axes()\n",
    "        sns.heatmap(matrix, ax = ax, annot = True, fmt='d', annot_kws={\"size\": 20}, cmap=colormap, cbar=False)\n",
    "        ax.set_title(classifier_name, fontsize= 15)\n",
    "        save_fig(\"{}\".format(classifier_name))\n",
    "else:\n",
    "    for i in range(len(evaluation_scores)):\n",
    "        classifier_name = str(classifiers[i]) # set classifier names\n",
    "        classifier_name = classifier_name[:classifier_name.find(\"(\")] \n",
    "        matrix = pd.DataFrame(confusion_matrices[i], columns = [\"classified as no mask\", \"classified as mask\"],\n",
    "                                        index = [\"no mask\", \"mask\"])\n",
    "\n",
    "        # Actual plot with seaborn\n",
    "        plt.figure(figsize = (5,5))\n",
    "        colormap = sns.color_palette(\"Reds\")\n",
    "        ax = plt.axes()\n",
    "        sns.heatmap(matrix, ax = ax, annot = True, fmt='d', annot_kws={\"size\": 20}, cmap=colormap, cbar=False)\n",
    "        ax.set_title(classifier_name, fontsize= 15)\n",
    "        save_fig(\"99_Toy_Dummy_{}\".format(classifier_name))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
